import dotenv from "dotenv";
import { NextResponse } from "next/server";
import { Configuration, OpenAIApi } from "openai";
import { auth, currentUser } from "@clerk/nextjs";

import { MemoryManager } from "@/lib/memory";
import { rateLimit } from "@/lib/rate-limit";
import prismadb from "@/lib/prismadb";

dotenv.config({ path: `.env` });

const configuration = new Configuration({
  apiKey: process.env.OPENAI_API_KEY,
});

const openai = new OpenAIApi(configuration);

export async function POST(
  request: Request,
  { params }: { params: { chatId: string } }
) {
  try {
    const { prompt } = await request.json();
    const user = await currentUser();

    if (!user || !user.firstName || !user.id) {
      return new NextResponse("Unauthorized", { status: 401 });
    }

    const identifier = request.url + "-" + user.id;
    const { success } = await rateLimit(identifier);

    if (!success) {
      return new NextResponse("Rate limit exceeded", { status: 429 });
    }

    const companion = await prismadb.companion.update({
      where: {
        id: params.chatId,
      },
      data: {
        messages: {
          create: {
            content: prompt,
            role: "user",
            userId: user.id,
          },
        },
      },
    });

    if (!companion) {
      return new NextResponse("Companion not found", { status: 404 });
    }

    const SYSTEM_MESSAGE = `ONLY generate plain sentences. I need you to follow the output patterns. I want the output to be as close to the character as possible, but twice as long the example outputs. Always follow this formla for the output: ${companion.description} [emotion]: [output] . Always use the author's full name. \nRole:\n${companion.instructions}\nOutput Pattern:\n${companion.seed})`;
    
    // const SEED_CHAT = `.\n${companion.seed}`;

    // const SYSTEM_MESSAGE = `${PREAMBLE}\n${SEED_CHAT}`;

    console.log(SYSTEM_MESSAGE);

    const messages = [
      {
        role: "system" as const,
        content: SYSTEM_MESSAGE,
      },
      {
        role: "user" as const,
        content: prompt,
      },
    ];

    const response = await openai.createChatCompletion({
      model: "gpt-3.5-turbo",
      messages,
    });

    const aiResponse = response.data.choices[0]?.message?.content;

    if (aiResponse) {
      await prismadb.companion.update({
        where: {
          id: params.chatId,
        },
        data: {
          messages: {
            create: {
              content: aiResponse,
              role: "system",
              userId: user.id,
            },
          },
        },
      });
    }

    var Readable = require("stream").Readable;

    let s = new Readable();
    s.push(aiResponse);
    s.push(null);

    return new NextResponse(aiResponse);
  } catch (error) {
    console.error('[CONVERSATION_ERROR]', error);
    return new NextResponse("Internal Error", { status: 500 });
  }
};
